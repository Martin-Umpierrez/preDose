---
title: "exeval_ppk"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{exeval_ppk}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This document presents a case of study to illustrates the external evaluation of a PPK model. The model and data come from Han, Nayoung, et al. "Prediction of the tacrolimus population pharmacokinetic parameters according to CYP3A5 genotype and clinical factors using NONMEM in adult kidney transplant recipients." European journal of clinical pharmacology 69.1 (2013): 53-63.

## Data and model 

First, we need to load the data and the model in `mrgsolve` format, both are preloaded in `preDose`package so they can be loaded usint `data()` funciton. 


```{r}
library(tidyverse)
library(preDose)

# load data and model code 
data(data_tacHAN2011)
data(model_tacHAN2011)
```

Data consist in records for 49 patients, most of them meassured in 6 occassions and 2 or 3 times per ocassion.  (TODO: EXPLAIN REQUIRED DATA FORMAT)

```{r}
# Max OCC per ID 
data_tacHAN2011 |> 
  select(ID, OCC) |> 
  group_by(ID) |> 
  summarise( OCC = max(OCC) )  |> 
  group_by(OCC) |> 
  count()

# add a relevant plot of the data? 
```

The model object is simply a character string describing the PPK model in a format that `mrgsolve::mcode()` can interpret, 

```{r}
# PPK model text  
str(model_tacHAN2011)
```

## External evaluation 
Explain: 
  - external evaluation idea
  - evaluation type options
  - assesment options 

The whole procedure can be done calling the `exeval_ppk()` function, its minimal arguments are the model name and code, the data, 
and the type of evaluation and assesment, 
```{r}
res <- exeval_ppk(model_name = "HAN2011",
                  model_code = model_tacHAN2011,
                  data = data_tacHAN2011,
                  evaluation_type= "Progressive", 
                  assessment='Bayesian_forecasting', 
                  verbose = FALSE )
```

## Results 

```{r}
res
```

Make some plots 
```{r}
metrics_Plot(res$metrics, type = "bias_barplot")
```

## Compare models 

```{r}
source("inst/model_examples/ZuoX_etal_2013.R")

resZ <- exeval_ppk(model_name = "ZuoX",
                  model_code = ZuoX_etalfull_noCYP3A4,
                  data = data_tacHAN2011,
                  evaluation_type= "Progressive",                  assessment='Bayesian_forecasting' )

resALL <- list(res, resZ) |> combine_metrics()  

plot_combined(resALL, 'bias_barplot')
```


Finally, `select_best_models()` function selects the best models from a dataframe of combined metrics based on a specified ranking metric.\
It requires a dataframe containing model evaluation metrics and the name of the metric to use for ranking.

Optionally, you can specify a particular occasion to focus on and the number of top models to select.

```{r model_selection, echo=TRUE, message=FALSE, warning=TRUE}

Best_fit <- select_best_models(resALL, metric = "rBIAS", top_n = 1)

Best_fit
```

## Intermediate steps in external evaluation process

### Calculate individual parameters with `run_MAP_estimations`

The `run_MAP_estimations()` function returns a list with four elements:

-   **Observed data per occasion**: Includes the observed values for each individual in each occasion.

-   **Treatments per occasion**: Contains information on the treatments administered in each occasion.

-   **Estimated individual parameters**: Provides the MAP-estimated values of individual parameters for each subject and occasion.

-   **Mandatory** Used evaluation method (Progressive, Most_Recent_Progressive, Cronologic_Ref, Most_Recent_rEF) 

```{r map_estim, echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
map.est <- run_MAP_estimations(model_name = "Test_Model",
                               model_code = Han_etal_test,
                               tool = "mapbayr",
                               data = external_data_mapbayr,
                               evaluation_type= "Progressive") 
```

### Update Individual Models with Estimated Parameters

Use `actualize_model()` to update each individual model using the parameters obtained from `run_MAP_estimations()`.

```{r indiviudal_Actualization, echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
updt.md = actualize_model(map.est, evaluation_type = "Progressive") #### Individual Models
```

### Simulate Observed Concentrations
To simulate individual concentration profiles for each subject (ID) across all occasions (OCC), the `run_ind_simulations()` function requires the results from `run_MAP_estimations()` and updated individual parameters object from `actualize_model()`.

```{r Simulate, echo=TRUE, message=FALSE, warning=FALSE, error=FALSE, cache=TRUE}
sim = run_ind_simulations(updt.md, 
                          map.est,
                          assessment = "Bayesian_forecasting") # Simulate for every ID in every OCC

```

### Calculate Metrics Across Occasions
Use `metrics_occ()` to assess predictive performance by computing key metrics for each occasion.

```{r calcualte_metrics, echo=TRUE, message=FALSE}
metrics = metrics_occ(simulations= sim,
                      assessment= "Bayesian_forecasting",
                      tool="mapbayr") # Simulate for every ID in every OCC


```